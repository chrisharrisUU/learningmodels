# Learning models

Some simulations of learning models on a two-armed bandit task.  

The bandit task consists of two independent arms. Particular to these simulations is that both arms are identical in that they have the exact same outcome probability.

The learnings models simulated so far are:  
 * A **Rescorla-Wagner** model, for which I heavily relied on [this](http://www.hannekedenouden.ruhosting.nl/RLtutorial/Instructions.html) tutorial  
 * A **Bayesian** learning model  
 * **BIAS**, an aggregation-based learning model:  
 Fiedler, K. (1996). Explaining and simulating judgment biases as an aggregation phenomenon in probabilistic, multiple-cue environments. *Psychological Review, 103*(1), 193-214.  
 * MINERVA-DM:  
 Dougherty, M. R. P., Gettys, C. F., & Ogden, E. E. (1999). MINERVA-DM: A memory processes model for judgments of likelihood. *Psychological Review, 106*(1), 180-209.
 
 Please note that this is very much work in progress.
